{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-WKVp4Uukcl"
      },
      "source": [
        "#Install Server Requirements\n",
        "This should be run on a minimum of a T4 runtime, though it will run on a CPU only session, however long TTS generations may time out/error.\n",
        "\n",
        "This is a **work in progress**. Known issues:\n",
        "\n",
        "- The 1st TTS generation has a brief stutter.\n",
        "- RVC is not yet working.\n",
        "- Transcoding/ffmpeg isnt working.\n",
        "- Things yet to do on selecting your first model and other configuration setups.\n",
        "\n",
        "If you enable DeepSpeed for XTTS models, DeepSpeed has to compile on the 1st TTS generation which can take about 90 seconds. After that it should be fine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6ls-RHTQeZv",
        "outputId": "04e8bd03-b270-42a2-db95-ac65aac390a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************************************\n",
            "** Server requirements installed ***\n",
            "*** Please proceed to next step ****\n",
            "************************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@markdown Click the `Play button` to the left of this message to install the requirements.<br><br>\n",
        "#@markdown **OPTIONAL** Mounting your Google Drive allows you to drag and drop samples/models via the `drive/Mydrive` path. This allows you<br>\n",
        "#@markdown to store or use specific audio samples or finetuned models.<br>\n",
        "#@markdown **Audio samples** need to be placed in `alltalk_tts/voices`<br>\n",
        "#@markdown **XTTS models** need to be placed in `alltalk_tts/models/xtts/{yourmodelfolderhere}`<br>\n",
        "mount_gdrive = True #@param{type:\"boolean\"}\n",
        "\n",
        "if mount_gdrive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "from IPython.display import clear_output\n",
        "print(\"*******************************************************************\")\n",
        "print(\"** Installing server requirements. This will take 5-10 minutes ****\")\n",
        "print(\"*******************************************************************\")\n",
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 libaio-dev espeak-ng > '/dev/null' 2>&1\n",
        "clear_output()\n",
        "print(\"************************\")\n",
        "print(\"*** Cloning AllTalk ****\")\n",
        "print(\"************************\\n\")\n",
        "!git clone -b alltalkbeta https://github.com/erew123/alltalk_tts\n",
        "clear_output()\n",
        "print(\"\\n********************************\")\n",
        "print(\"*** Installing Requirements ****\")\n",
        "print(\"********************************\\n\")\n",
        "!python -m pip install --upgrade \"pip<24.1\"\n",
        "!pip install --quiet -r /content/alltalk_tts/system/requirements/requirements_colab.txt\n",
        "clear_output()\n",
        "print(\"\\n*****************************\")\n",
        "print(\"*** Installing DeepSpeed ****\")\n",
        "print(\"*****************************\\n\")\n",
        "!pip install deepspeed\n",
        "!pip install orjson\n",
        "!pip install faiss-cpu\n",
        "!pip install fairseq\n",
        "clear_output()\n",
        "print(\"\\n******************************\")\n",
        "print(\"*** Installing Cloudflare ****\")\n",
        "print(\"******************************\\n\")\n",
        "# Install cloudflare\n",
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb > '/dev/null' 2>&1\n",
        "!apt install ./cloudflared-linux-amd64.deb aria2 > '/dev/null' 2>&1\n",
        "!rm cloudflared-linux-amd64.deb > '/dev/null' 2>&1\n",
        "!python -m spacy download en_core_web_md\n",
        "clear_output()\n",
        "print(\"\\n***************************\")\n",
        "print(\"*** Installing Cutlass ****\")\n",
        "print(\"***************************\\n\")\n",
        "# Clone the CUTLASS repository\n",
        "!git clone https://github.com/NVIDIA/cutlass.git\n",
        "!export CUTLASSPATH=/content/cutlass\n",
        "!sudo curl -L https://github.com/BtbN/FFmpeg-Builds/releases/download/latest/ffmpeg-master-latest-linux64-gpl.tar.xz -o /usr/local/bin/ffmpeg.tar.xz\n",
        "clear_output()\n",
        "%cd /usr/local/bin/\n",
        "clear_output()\n",
        "!7z e /usr/local/bin/ffmpeg.tar.xz -y\n",
        "clear_output()\n",
        "!7z e /usr/local/bin/ffmpeg.tar -y\n",
        "clear_output()\n",
        "!sudo chmod a+rx /usr/local/bin/ffmpeg\n",
        "clear_output()\n",
        "!pip uninstall jax -y\n",
        "clear_output()\n",
        "print(\"************************************\")\n",
        "print(\"** Server requirements installed ***\")\n",
        "print(\"*** Please proceed to next step ****\")\n",
        "print(\"************************************\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nk26r66RQ23"
      },
      "source": [
        "\n",
        "# Start AllTalk TTS Server\n",
        "\n",
        "This will start the AllTalk API and Gradio Web interface. From here you can download models, generate TTS and use external applications via the API address.\n",
        "\n",
        "The AllTalk API address is what you would use in Kobold, SillyTavern, TGWUI's Remote extension etc if you want to generate TTS with those applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9PCQhSoiWvhL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61cfe28e-94f2-4ede-8d14-df8b95af56dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AllTalk TTS] \u001b[94m    _    _ _ \u001b[1;35m_____     _ _     \u001b[0m  _____ _____ ____  \n",
            "[AllTalk TTS] \u001b[94m   / \\  | | |\u001b[1;35m_   _|_ _| | | __ \u001b[0m |_   _|_   _/ ___| \n",
            "[AllTalk TTS] \u001b[94m  / _ \\ | | |\u001b[1;35m | |/ _` | | |/ / \u001b[0m   | |   | | \\___ \\ \n",
            "[AllTalk TTS] \u001b[94m / ___ \\| | |\u001b[1;35m | | (_| | |   <  \u001b[0m   | |   | |  ___) |\n",
            "[AllTalk TTS] \u001b[94m/_/   \\_\\_|_|\u001b[1;35m |_|\\__,_|_|_|\\_\\ \u001b[0m   |_|   |_| |____/ \n",
            "[AllTalk TTS] \n",
            "[AllTalk TTS] \u001b[92mStart-up Mode     : \u001b[93mStandalone mode\u001b[0m\n",
            "[AllTalk TTS] Detected Colab/Docker environment - automatically selecting Piper\n",
            "Attempting to download: https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/en/en_US/ljspeech/high/en_US-ljspeech-high.onnx?download=true (Attempt 1/3)\n",
            "Downloading en_US-ljspeech-high.onnx (Attempt 1/3): 100% 114M/114M [00:01<00:00, 95.8MiB/s]\n",
            "Download completed: /content/alltalk_tts/models/piper/en_US-ljspeech-high.onnx\n",
            "Attempting to download: https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/en/en_US/ljspeech/high/en_US-ljspeech-high.onnx.json?download=true.json (Attempt 1/3)\n",
            "Downloading en_US-ljspeech-high.onnx.json (Attempt 1/3): 100% 4.97k/4.97k [00:00<00:00, 12.6MiB/s]\n",
            "Download completed: /content/alltalk_tts/models/piper/en_US-ljspeech-high.onnx.json\n",
            "[AllTalk TTS]\n",
            "[AllTalk TTS] \u001b[93mIf you have you have UPGRADED from v1 ensure you have re-installed\u001b[0m\n",
            "[AllTalk TTS] \u001b[93mthe requirements. Otherwise you will get failures and errors!\u001b[0m\n",
            "[AllTalk TTS] \u001b[93mOn Linux ignore the \u001b[0m'sparse_attn requires a torch version' \u001b[93mand\u001b[0m\n",
            "[AllTalk TTS] \u001b[0m'using untested triton version' \u001b[93mmessages.\u001b[0m\n",
            "[AllTalk TTS]\n",
            "[AllTalk TTS] \u001b[92mWAV file deletion :\u001b[93m Disabled\u001b[0m\n",
            "[AllTalk TTS] \u001b[92mGithub updated    :\u001b[93m 12th February 2025 at 21:11 \u001b[92mBranch:\u001b[93m alltalkbeta\u001b[0m\n",
            "[AllTalk TTS] \n",
            "[AllTalk TTS] \u001b[94mGoogle Colab Detected\u001b[00m\n",
            "[AllTalk TTS] \n",
            "[AllTalk ENG] \u001b[92mTranscoding       :\u001b[93m ffmpeg found\u001b[0m\n",
            "2025-02-24 08:02:18.543947: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740384138.777524    3100 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740384138.839809    3100 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-24 08:02:19.321122: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[AllTalk ENG] \u001b[92mDeepSpeed version :\u001b[93m 0.16.4 \u001b[0m\n",
            "[AllTalk ENG] \u001b[92mPython Version    :\u001b[93m 3.11.11\u001b[0m\n",
            "[AllTalk ENG] \u001b[92mPyTorch Version   :\u001b[93m 2.5.1+cu124\u001b[0m\n",
            "[AllTalk ENG] \u001b[92mCUDA Version      :\u001b[93m 12.4\u001b[0m\n",
            "[AllTalk ENG]\n",
            "[AllTalk ENG]\u001b[94m Model/Engine :\u001b[93m Piper\u001b[94m Ready\u001b[0m\n",
            "[AllTalk ENG] \u001b[94mLoad time :\u001b[93m 0.00 seconds.\u001b[0m\n",
            "[AllTalk TTS] \n",
            "[AllTalk TTS] \u001b[94mAPI Address :\u001b[00m \u001b[92mhttps://tanzania-nickname-dispatched-trap.trycloudflare.com\u001b[00m\n",
            "[AllTalk TTS] \u001b[94mGradio Light:\u001b[00m \u001b[92mhttps://oc-cinema-bodies-marion.trycloudflare.com\u001b[00m\n",
            "[AllTalk TTS] \u001b[94mGradio Dark :\u001b[00m \u001b[92mhttps://oc-cinema-bodies-marion.trycloudflare.com?__theme=dark\u001b[00m\n",
            "[AllTalk TTS] \n",
            "[AllTalk TTS] \u001b[94mAllTalk WIKI:\u001b[00m \u001b[92mhttps://github.com/erew123/alltalk_tts/wiki\u001b[00m\n",
            "[AllTalk TTS] \u001b[94mErrors Help :\u001b[00m \u001b[92mhttps://github.com/erew123/alltalk_tts/wiki/Error-Messages-List\u001b[00m\n",
            "[AllTalk TTS] \n",
            "themes%2Ftheme_schema%400.0.1.json: 100% 13.1k/13.1k [00:00<00:00, 53.3MB/s]\n",
            "[AllTalk TTS] Please use \u001b[91mCtrl+C\u001b[0m when exiting AllTalk otherwise a\n",
            "[AllTalk TTS] subprocess may continue running in the background.\n",
            "[AllTalk TTS] \n",
            "[AllTalk TTS] Server Ready\n"
          ]
        }
      ],
      "source": [
        "#@markdown Click the `Play button` to the left of this message to start AllTalk API and Gradio Interface<br>\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "import threading\n",
        "import time\n",
        "\n",
        "def keep_alive():\n",
        "    while True:\n",
        "        time.sleep(60)  # Run every 60 seconds (adjust as needed)\n",
        "\n",
        "keep_alive_thread = threading.Thread(target=keep_alive)\n",
        "keep_alive_thread.start()\n",
        "\n",
        "Tunnel = \"cloudflare\"\n",
        "host = \"127.0.0.1\"\n",
        "ports = [7851, 7852]\n",
        "tunnel_urls = []\n",
        "\n",
        "# Starting tunnels for each port.\n",
        "for port in ports:\n",
        "    if Tunnel == \"cloudflare\":\n",
        "        !nohup cloudflared tunnel --url http://{host}:{port} > lt_{port}.log 2>&1 &\n",
        "    else:\n",
        "        !nohup npx lt -p {port} > lt_{port}.log 2>&1 &\n",
        "\n",
        "# Wait a couple of seconds for the tunnels to initialize.\n",
        "time.sleep(10)\n",
        "\n",
        "# Extract URLs for each tunnel.\n",
        "for port in ports:\n",
        "    log_file = f'lt_{port}.log'\n",
        "    with open(log_file, 'r') as testwritefile:\n",
        "        log_content = testwritefile.read()\n",
        "\n",
        "        # Use regular expressions to find the URL.\n",
        "        if Tunnel == \"cloudflare\":\n",
        "            url_match = re.search(r'(https://[-a-z0-9]+\\.trycloudflare\\.com)', log_content)\n",
        "        else:\n",
        "            url_match = re.search(r'your url is: (https?://\\S+)', log_content)\n",
        "\n",
        "        if url_match:\n",
        "            tunnel_url = url_match.group(1)\n",
        "            tunnel_urls.append(tunnel_url)\n",
        "        else:\n",
        "            print(f\"URL for port {port} not found.\")\n",
        "\n",
        "# Save the tunnel URLs to a JSON file.\n",
        "try:\n",
        "    # Try to open the JSON file for reading.\n",
        "    with open('/content/alltalk_tts/googlecolab.json', 'r') as f:\n",
        "        data = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    # If the file doesn't exist, create an empty dictionary.\n",
        "    data = {}\n",
        "\n",
        "data['google_ip_address'] = tunnel_urls\n",
        "\n",
        "# Write the modified data (or newly created data) back to the file.\n",
        "with open('/content/alltalk_tts/googlecolab.json', 'w') as f:\n",
        "    json.dump(data, f)\n",
        "\n",
        "host = \"0.0.0.0\"\n",
        "\n",
        "if Tunnel == \"localtunnel\":\n",
        "    print(\"Before you copy the link above click on it and copy that ip:\")\n",
        "    !curl ipv4.icanhazip.com\n",
        "\n",
        "# Start API server.\n",
        "!python /content/alltalk_tts/script.py\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KEmLaKsb-6pX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start XTTS model Finetuning\n",
        "\n",
        "Starts the Finetuning application for XTTS models.\n",
        "\n",
        "You can either run the `Start AllTalk` to download the base XTTS model(s) for finetuning. Or you can use the folder icon on the left hand side of the screen and upload an XTTS model that you want to finetune. If you are manually uploading a model, you would place your model files in `models/xtts/{yourmodelfolderhere}` and you will need all the models files in that folder `config.json, dvae.pth, mel_stats.pth, model.pth, speakers_xtts.pth, vocab.json`. Without 1x model available, Finetuning will not start.\n",
        "\n",
        "Likewise you can download your finetuned model from there, OR copy it to your Google Drive after finetuning, for later use in AllTalk. To access the Finetuning Gradio interface, connect to the `Google Colab Finetuning url` when Finetuning has started."
      ],
      "metadata": {
        "id": "gDzNPMwM7qvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Click the `Play button` to the left of this message to start Finetuning<br>\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "import threading\n",
        "import time\n",
        "\n",
        "def keep_alive():\n",
        "    while True:\n",
        "        time.sleep(60)  # Run every 60 seconds (adjust as needed)\n",
        "\n",
        "keep_alive_thread = threading.Thread(target=keep_alive)\n",
        "keep_alive_thread.start()\n",
        "\n",
        "Tunnel = \"cloudflare\"\n",
        "host = \"127.0.0.1\"\n",
        "ports = [7052]\n",
        "tunnel_urls = []\n",
        "\n",
        "# Starting tunnels for each port.\n",
        "for port in ports:\n",
        "    if Tunnel == \"cloudflare\":\n",
        "        !nohup cloudflared tunnel --url http://{host}:{port} > lt_{port}.log 2>&1 &\n",
        "    else:\n",
        "        !nohup npx lt -p {port} > lt_{port}.log 2>&1 &\n",
        "\n",
        "# Wait a couple of seconds for the tunnels to initialize.\n",
        "time.sleep(10)\n",
        "\n",
        "# Extract URLs for each tunnel.\n",
        "for port in ports:\n",
        "    log_file = f'lt_{port}.log'\n",
        "    with open(log_file, 'r') as testwritefile:\n",
        "        log_content = testwritefile.read()\n",
        "\n",
        "        # Use regular expressions to find the URL.\n",
        "        if Tunnel == \"cloudflare\":\n",
        "            url_match = re.search(r'(https://[-a-z0-9]+\\.trycloudflare\\.com)', log_content)\n",
        "        else:\n",
        "            url_match = re.search(r'your url is: (https?://\\S+)', log_content)\n",
        "\n",
        "        if url_match:\n",
        "            tunnel_url = url_match.group(1)\n",
        "            tunnel_urls.append(tunnel_url)\n",
        "            print(f\"Google Colab Finetuning url: {tunnel_url}\\n\")\n",
        "            print(f\"********************************************************************\")\n",
        "            print(f\"**** Use the above URL to connect to Finetuning on Google Colab ****\")\n",
        "            print(f\"********************************************************************\")\n",
        "            print(f\"************* Now starting the Finetuning Application **************\")\n",
        "            print(f\"********************************************************************\\n\")\n",
        "        else:\n",
        "            print(f\"URL for port {port} not found.\")\n",
        "\n",
        "# Save the tunnel URLs to a JSON file.\n",
        "try:\n",
        "    # Try to open the JSON file for reading.\n",
        "    with open('/content/alltalk_tts/googlecolab.json', 'r') as f:\n",
        "        data = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    # If the file doesn't exist, create an empty dictionary.\n",
        "    data = {}\n",
        "\n",
        "data['google_ip_address'] = tunnel_urls\n",
        "\n",
        "# Write the modified data (or newly created data) back to the file.\n",
        "with open('/content/alltalk_tts/googlecolab.json', 'w') as f:\n",
        "    json.dump(data, f)\n",
        "\n",
        "host = \"0.0.0.0\"\n",
        "\n",
        "if Tunnel == \"localtunnel\":\n",
        "    print(\"Before you copy the link above click on it and copy that ip:\")\n",
        "    !curl ipv4.icanhazip.com\n",
        "\n",
        "# Start API server.\n",
        "!python /content/alltalk_tts/finetune.py\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Dewvq5s38Sfd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}